{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16bc679",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac814304",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Datasets/data.txt\"\n",
    "\n",
    "texts = []\n",
    "\n",
    "with(open(data_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f):\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            texts.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964cef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I never thought I’d see you again after all these years.',\n",
       "  'Life has strange ways of bringing people back together when least expected.',\n",
       "  'The evidence doesn’t add up. The fingerprints on the weapon belong to someone who wasn’t even at the crime scene that night.',\n",
       "  'We’ve tried every possible treatment, but his condition remains stable. The next few hours will be critical for his full recovery.',\n",
       "  'Your mission is simple: retrieve the stolen data, avoid enemy surveillance, and ensure nobody knows you were ever there.'],\n",
       " 552)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5], len(texts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72140db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c627a",
   "metadata": {},
   "source": [
    "We can See a lot of noise of blank strings...So preprocessing Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccc29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9?.!,']+\", \" \", text)\n",
    "    text = re.sub(r\"[()]\", \"\", text)\n",
    "    text = re.sub(r\"\\.{2,}\", \".\", text)\n",
    "    text = re.sub(r\"\\,{2,}\", \",\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77f1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "texts = [clean_text(text) for text in texts]\n",
    "random.seed(42)\n",
    "random.shuffle(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b52bc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i really appreciate your help with this.',\n",
       " 'i heard there s a new caf opening downtown next weekend.',\n",
       " 'do you want to split the tasks to get them done faster?',\n",
       " 'it s just a flesh wound.',\n",
       " 'could you help me carry these boxes upstairs?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b66a027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 14:36:35.916936: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-03 14:36:35.941583: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-03 14:36:35.941613: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-03 14:36:35.941634: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-03 14:36:35.946581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1502\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 5000, oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ebaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d9b498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 62, 110, 12, 111, 21, 10],\n",
       " [5, 168, 37, 8, 7, 66, 633, 634, 386, 63, 76],\n",
       " [34, 3, 77, 4, 267, 2, 268, 4, 49, 143, 269, 270],\n",
       " [9, 8, 59, 7, 635, 636],\n",
       " [64, 3, 111, 17, 387, 144, 637, 638],\n",
       " [34, 3, 23, 42, 271, 13, 2, 76],\n",
       " [2, 388, 639, 100, 35, 10, 640, 6, 44, 641, 642, 643, 60],\n",
       " [5, 27, 389, 3, 24, 37, 26, 42, 272, 201],\n",
       " [6, 390, 38, 391, 644],\n",
       " [2, 202, 15, 645, 646, 3]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b03f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(sequences):\n",
    "    ngrams = []\n",
    "    for seq in sequences:\n",
    "        for i in range(1, len(seq)):\n",
    "            n_gram_seq = seq[:i + 1]\n",
    "            ngrams.append(n_gram_seq)\n",
    "    \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c6b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = get_ngrams(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88354eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 62],\n",
       " [5, 62, 110],\n",
       " [5, 62, 110, 12],\n",
       " [5, 62, 110, 12, 111],\n",
       " [5, 62, 110, 12, 111, 21],\n",
       " [5, 62, 110, 12, 111, 21, 10],\n",
       " [5, 168],\n",
       " [5, 168, 37],\n",
       " [5, 168, 37, 8],\n",
       " [5, 168, 37, 8, 7]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d733216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(len(seq) for seq in train_tokens)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19813a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 160 is a big number so we will keep it to 40\n",
    "# max_length = 40\n",
    "\n",
    "# train_tokens = [token for token in train_tokens if len(token) <= max_length]\n",
    "# val_tokens = [token for token in val_tokens if len(token) <= max_length]\n",
    "# test_tokens = [token for token in test_tokens if len(token) <= max_length]\n",
    "\n",
    "# print(f\"Final train size: {len(train_tokens)}\")\n",
    "# print(f\"Final validation size: {len(val_tokens)}\")\n",
    "# print(f\"Final test size: {len(test_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d8245ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tokens shape: (5433, 24)\n"
     ]
    }
   ],
   "source": [
    "train_tokens = pad_sequences(train_tokens, maxlen=max_length, padding='pre')\n",
    "print(f\"Train tokens shape: {train_tokens.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843912a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  62],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   5,  62, 110],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   5,  62, 110,  12],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   5,  62, 110,  12, 111],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   5,  62, 110,  12, 111,  21],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   5,  62, 110,  12, 111,  21,  10],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   5, 168],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   5, 168,  37],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   5, 168,  37,   8],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   5, 168,  37,   8,   7]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9273e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5433, 23), y_train shape: (5433,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train = train_tokens[:, :-1]\n",
    "y_train = train_tokens[:, -1]\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97570892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   5],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   5,  62],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   5,  62, 110],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   5,  62, 110,  12],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   5,  62, 110,  12, 111]], dtype=int32),\n",
       " array([ 62, 110,  12, 111,  21], dtype=int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8a6b1",
   "metadata": {},
   "source": [
    "Using GLOVE 6B 100D pretrained model as embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e085508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set your file path\n",
    "embedding_index = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coeffs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df08be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # Random initialization for OOV words (optional)\n",
    "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20bc5281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1502, 100),\n",
       " array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.50039658e-01, -1.92815195e-01,  2.80954238e-02,\n",
       "         -1.48646393e-01,  8.23851689e-01, -8.34139600e-01,\n",
       "          3.75097026e-02, -1.53725999e+00,  3.79082347e-01,\n",
       "          6.21680390e-02, -5.25066120e-02,  4.48977871e-01,\n",
       "         -7.50500997e-02, -1.03199314e+00,  1.75975746e+00,\n",
       "          6.46436410e-01,  1.00973456e+00, -2.00320471e-01,\n",
       "         -2.01988066e-01, -4.26681019e-01, -8.13641032e-01,\n",
       "          5.45262273e-01, -5.94576553e-01,  5.84972004e-02,\n",
       "          4.24327430e-01, -6.86088289e-01, -1.90809983e-01,\n",
       "         -5.33855114e-01, -2.24463247e-01,  5.95294912e-01,\n",
       "         -2.87639408e-01, -9.06235962e-01, -1.73079227e-01,\n",
       "          5.79458528e-02,  9.90082403e-01, -1.12196638e-02,\n",
       "         -4.93668513e-01, -6.51678900e-02,  5.46628085e-01,\n",
       "          1.85940740e-01,  7.19826475e-01,  1.61960404e-01,\n",
       "         -1.85554393e-01, -1.81032868e-01,  2.36755776e-01,\n",
       "         -8.95175880e-01,  1.18838768e+00, -2.83802252e-01,\n",
       "         -1.09285291e+00, -4.32509244e-02, -8.31152483e-01,\n",
       "          5.27272786e-01, -8.12079637e-01, -4.70307873e-01,\n",
       "          3.15831801e-01,  1.20233880e+00, -1.22612879e-01,\n",
       "         -3.57399086e-01,  6.29059872e-01, -4.33314291e-01,\n",
       "          1.80842836e-01,  2.69033211e-01, -6.71215950e-01,\n",
       "          2.32445119e-02,  6.51125365e-01,  2.22860231e-01,\n",
       "          6.25792686e-01,  4.57872907e-01, -1.79684604e-01,\n",
       "         -3.06926074e-01,  6.28382001e-02, -7.30026142e-01,\n",
       "          3.34665427e-01, -1.66567750e-01,  1.06552704e-02,\n",
       "          4.92555614e-01,  3.61612275e-01, -1.61095282e-01,\n",
       "          1.35751021e-01, -1.05474252e+00,  1.13963203e-02,\n",
       "          5.38311279e-01, -8.87655421e-01,  1.11884107e-01,\n",
       "          7.50482658e-01, -1.24327031e-01,  2.90410758e-01,\n",
       "          2.46535640e-01, -6.70664155e-01, -5.53754792e-01,\n",
       "          2.64153171e-01,  8.89134541e-01, -1.01410998e+00,\n",
       "          2.91313643e-01,  3.87786845e-01, -5.57405938e-02,\n",
       "         -3.77683765e-01, -1.06700659e+00,  6.14001735e-02,\n",
       "          2.82206122e-01],\n",
       "        [-3.81940007e-02, -2.44870007e-01,  7.28120029e-01,\n",
       "         -3.99610013e-01,  8.31720009e-02,  4.39530015e-02,\n",
       "         -3.91409993e-01,  3.34399998e-01, -5.75450003e-01,\n",
       "          8.74589980e-02,  2.87869990e-01, -6.73099980e-02,\n",
       "          3.09060007e-01, -2.63839990e-01, -1.32310003e-01,\n",
       "         -2.07570001e-01,  3.33950013e-01, -3.38479996e-01,\n",
       "         -3.17429990e-01, -4.83359993e-01,  1.46400005e-01,\n",
       "         -3.73039991e-01,  3.45770001e-01,  5.20410016e-02,\n",
       "          4.49460000e-01, -4.69709992e-01,  2.62800008e-02,\n",
       "         -5.41549981e-01, -1.55180007e-01, -1.41069993e-01,\n",
       "         -3.97219993e-02,  2.82770008e-01,  1.43930003e-01,\n",
       "          2.34640002e-01, -3.10209990e-01,  8.61729980e-02,\n",
       "          2.03970000e-01,  5.26239991e-01,  1.71639994e-01,\n",
       "         -8.23780000e-02, -7.17869997e-01, -4.15309995e-01,\n",
       "          2.03349993e-01, -1.27629995e-01,  4.13670003e-01,\n",
       "          5.51869988e-01,  5.79079986e-01, -3.34769994e-01,\n",
       "         -3.65590006e-01, -5.48569977e-01, -6.28919974e-02,\n",
       "          2.65839994e-01,  3.02049994e-01,  9.97749984e-01,\n",
       "         -8.04809988e-01, -3.02430010e+00,  1.25399996e-02,\n",
       "         -3.69419992e-01,  2.21670008e+00,  7.22010016e-01,\n",
       "         -2.49779999e-01,  9.21360016e-01,  3.45139988e-02,\n",
       "          4.67449993e-01,  1.10790002e+00, -1.93580002e-01,\n",
       "         -7.45749995e-02,  2.33530000e-01, -5.20620011e-02,\n",
       "         -2.20440000e-01,  5.71620017e-02, -1.58059999e-01,\n",
       "         -3.07980001e-01, -4.16249990e-01,  3.79720002e-01,\n",
       "          1.50059998e-01, -5.32119989e-01, -2.05500007e-01,\n",
       "         -1.25259995e+00,  7.16240034e-02,  7.05649972e-01,\n",
       "          4.97440010e-01, -4.20630008e-01,  2.61480004e-01,\n",
       "         -1.53799999e+00, -3.02230000e-01, -7.34380037e-02,\n",
       "         -2.83120006e-01,  3.71039987e-01, -2.52169997e-01,\n",
       "          1.62150003e-02, -1.70990005e-02, -3.89840007e-01,\n",
       "          8.74239981e-01, -7.25690007e-01, -5.10580003e-01,\n",
       "         -5.20280004e-01, -1.45899996e-01,  8.27799976e-01,\n",
       "          2.70619988e-01],\n",
       "        [-4.98860002e-01,  7.66020000e-01,  8.97509992e-01,\n",
       "         -7.85470009e-01, -6.85500026e-01,  6.26089990e-01,\n",
       "         -3.96550000e-01,  3.49130005e-01,  3.33339989e-01,\n",
       "         -4.52329993e-01,  6.12230003e-01,  7.59480000e-02,\n",
       "          2.25309998e-01,  1.63650006e-01,  2.80950010e-01,\n",
       "         -2.47580007e-01,  9.90089960e-03,  7.11080015e-01,\n",
       "         -7.58589983e-01,  8.74230027e-01,  3.10410000e-03,\n",
       "          3.57959986e-01, -3.52329999e-01, -6.65000021e-01,\n",
       "          3.84469986e-01,  6.26770020e-01, -5.15429974e-01,\n",
       "         -9.66530025e-01,  6.15170002e-01, -7.54549980e-01,\n",
       "         -1.23589998e-02,  1.11880004e+00,  3.57190013e-01,\n",
       "          7.17689982e-03,  2.02549994e-01,  5.01100004e-01,\n",
       "         -4.40459996e-01,  1.06610000e-01,  7.93910027e-01,\n",
       "         -8.09480011e-01, -1.56009998e-02, -2.28880003e-01,\n",
       "         -3.41980010e-01, -1.00650001e+00, -8.76299977e-01,\n",
       "          1.51649997e-01, -8.53390023e-02, -6.46499991e-01,\n",
       "         -1.67329997e-01, -1.44990003e+00, -6.59050001e-03,\n",
       "          4.81129996e-03, -1.24450000e-02,  1.04740000e+00,\n",
       "         -1.93810001e-01, -2.59910011e+00,  4.05279994e-01,\n",
       "          4.38030005e-01,  1.93320000e+00,  4.58139986e-01,\n",
       "         -4.88190018e-02,  1.43079996e+00, -7.86390007e-01,\n",
       "         -2.07920000e-01,  1.09000003e+00,  2.48160005e-01,\n",
       "          1.14870000e+00,  5.14810026e-01, -2.18319997e-01,\n",
       "         -4.57199991e-01,  1.38880000e-01, -2.63689995e-01,\n",
       "          1.36470005e-01, -6.05390012e-01,  9.95860025e-02,\n",
       "          2.33439997e-01,  1.36470005e-01, -1.84599996e-01,\n",
       "         -4.77339998e-02, -1.83919996e-01,  5.27190030e-01,\n",
       "         -2.88500011e-01, -1.07420003e+00, -4.67000008e-02,\n",
       "         -1.83019996e+00, -2.11970001e-01,  2.97999997e-02,\n",
       "         -3.09639990e-01, -4.33860004e-01, -3.64630014e-01,\n",
       "         -3.27380002e-01, -9.34270024e-03,  4.72050011e-01,\n",
       "         -5.16910017e-01, -5.91759980e-01, -3.23430002e-01,\n",
       "          2.00519994e-01, -4.11790013e-01,  4.05389994e-01,\n",
       "          7.85040021e-01],\n",
       "        [-1.89700007e-01,  5.00239991e-02,  1.90840006e-01,\n",
       "         -4.91839983e-02, -8.97369981e-02,  2.10060000e-01,\n",
       "         -5.49520016e-01,  9.83769968e-02, -2.01350003e-01,\n",
       "          3.42409998e-01, -9.26769972e-02,  1.60999998e-01,\n",
       "         -1.32679999e-01, -2.81599998e-01,  1.87370002e-01,\n",
       "         -4.29589987e-01,  9.60389972e-01,  1.39719993e-01,\n",
       "         -1.07809997e+00,  4.05180007e-01,  5.05389988e-01,\n",
       "         -5.50639987e-01,  4.84400004e-01,  3.80439997e-01,\n",
       "         -2.90549989e-03, -3.49420011e-01, -9.96960029e-02,\n",
       "         -7.83680022e-01,  1.03629994e+00, -2.31399998e-01,\n",
       "         -4.71210003e-01,  5.71259975e-01, -2.14540005e-01,\n",
       "          3.59580010e-01, -4.83190000e-01,  1.08749998e+00,\n",
       "          2.85239995e-01,  1.24470003e-01, -3.92480008e-02,\n",
       "         -7.67320022e-02, -7.63429999e-01, -3.24090004e-01,\n",
       "         -5.74899971e-01, -1.08930004e+00, -4.18110013e-01,\n",
       "          4.51200008e-01,  1.21119998e-01, -5.13670027e-01,\n",
       "         -1.33489996e-01, -1.13779998e+00, -2.87680000e-01,\n",
       "          1.67740002e-01,  5.58040023e-01,  1.53869998e+00,\n",
       "          1.88590009e-02, -2.97210002e+00, -2.42160007e-01,\n",
       "         -9.24950004e-01,  2.19919991e+00,  2.82339990e-01,\n",
       "         -3.47799987e-01,  5.16210020e-01, -4.33869988e-01,\n",
       "          3.68519992e-01,  7.45729983e-01,  7.21020028e-02,\n",
       "          2.79309988e-01,  9.25689995e-01, -5.03359996e-02,\n",
       "         -8.58560026e-01, -1.35800004e-01, -9.25509989e-01,\n",
       "         -3.39910001e-01, -1.03939998e+00, -6.72030002e-02,\n",
       "         -2.13789999e-01, -4.76900011e-01,  2.13770002e-01,\n",
       "         -8.40080023e-01,  5.25359996e-02,  5.92980027e-01,\n",
       "          2.96039999e-01, -6.76440001e-01,  1.39160007e-01,\n",
       "         -1.55040002e+00, -2.07650006e-01,  7.22199976e-01,\n",
       "          5.20560026e-01, -7.62209967e-02, -1.51940003e-01,\n",
       "         -1.31339997e-01,  5.86169995e-02, -3.18690002e-01,\n",
       "         -6.14189982e-01, -6.23929977e-01, -4.15479988e-01,\n",
       "         -3.81750017e-02, -3.98039997e-01,  4.76469994e-01,\n",
       "         -1.59830004e-01]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape, embedding_matrix[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb4254ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 14:36:42.862069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.866488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.867534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.869849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.870849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.871778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.943343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.944363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.945330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-03 14:36:42.946227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6166 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-07-03 14:36:43.061149: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_layer (Embedding  (None, 23, 100)           150200    \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 128)               84480     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_layer (Dense)         (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout_layer (Dropout)     (None, 128)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1502)              193758    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 445462 (1.70 MB)\n",
      "Trainable params: 295006 (1.13 MB)\n",
      "Non-trainable params: 150456 (587.72 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from functools import partial\n",
    "\n",
    "embedding_dim = 100\n",
    "Embedding = partial(Embedding, weights=[embedding_matrix], trainable=False)\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length-1, name='embedding_layer'),\n",
    "    Bidirectional(LSTM(64, name='bidirectional_lstm')),\n",
    "    Dense(128, activation='relu', name='dense_layer'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3, name='dropout_layer'),\n",
    "    Dense(vocab_size, activation='softmax', name='output_layer')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a97205e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d5cb449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: tensorboard_logs/glove6B100D_lstm/20250703-143643\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 14:36:45.319115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2025-07-03 14:36:45.987632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x70f78cb6b100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-03 14:36:45.987657: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-03 14:36:45.990532: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-03 14:36:46.063261: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 4s 4ms/step - loss: 6.7596 - accuracy: 0.0468 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 5.7144 - accuracy: 0.0994 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 5.2681 - accuracy: 0.1178 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 4.8285 - accuracy: 0.1439 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 4.4173 - accuracy: 0.1701 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 3.9863 - accuracy: 0.1999 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 3.6227 - accuracy: 0.2395 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 3.3084 - accuracy: 0.2812 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 3.0070 - accuracy: 0.3116 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 2.7452 - accuracy: 0.3655 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 2.4901 - accuracy: 0.4127 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 2.3208 - accuracy: 0.4438 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 2.1551 - accuracy: 0.4734 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 2.0225 - accuracy: 0.5049 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.8849 - accuracy: 0.5244 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.7935 - accuracy: 0.5485 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.6993 - accuracy: 0.5796 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.6101 - accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.5699 - accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.5043 - accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.4091 - accuracy: 0.6315 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.3928 - accuracy: 0.6300 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.3588 - accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.2863 - accuracy: 0.6685 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.2504 - accuracy: 0.6694 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.2090 - accuracy: 0.6882 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.1734 - accuracy: 0.6987 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.1425 - accuracy: 0.6952 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.1057 - accuracy: 0.7070 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.0780 - accuracy: 0.7158 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.0652 - accuracy: 0.7221 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.0349 - accuracy: 0.7265 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "337/340 [============================>.] - ETA: 0s - loss: 1.0566 - accuracy: 0.7226\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 1.0546 - accuracy: 0.7232 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.8416 - accuracy: 0.7760 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.7832 - accuracy: 0.7858 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "333/340 [============================>.] - ETA: 0s - loss: 0.7904 - accuracy: 0.7851\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.7909 - accuracy: 0.7852 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.8110 - lr: 2.5000e-04\n",
      "Epoch 38/50\n",
      "336/340 [============================>.] - ETA: 0s - loss: 0.7018 - accuracy: 0.8078\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.7017 - accuracy: 0.8082 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6487 - accuracy: 0.8209 - lr: 1.2500e-04\n",
      "Epoch 40/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6248 - accuracy: 0.8262 - lr: 1.2500e-04\n",
      "Epoch 41/50\n",
      "331/340 [============================>.] - ETA: 0s - loss: 0.6310 - accuracy: 0.8252\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6291 - accuracy: 0.8246 - lr: 1.2500e-04\n",
      "Epoch 42/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6206 - accuracy: 0.8270 - lr: 6.2500e-05\n",
      "Epoch 43/50\n",
      "331/340 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.8233\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6212 - accuracy: 0.8231 - lr: 6.2500e-05\n",
      "Epoch 44/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6093 - accuracy: 0.8297 - lr: 3.1250e-05\n",
      "Epoch 45/50\n",
      "340/340 [==============================] - 2s 5ms/step - loss: 0.5971 - accuracy: 0.8345 - lr: 3.1250e-05\n",
      "Epoch 46/50\n",
      "339/340 [============================>.] - ETA: 0s - loss: 0.6015 - accuracy: 0.8304\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6028 - accuracy: 0.8297 - lr: 3.1250e-05\n",
      "Epoch 47/50\n",
      "333/340 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.8311\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.6030 - accuracy: 0.8301 - lr: 1.5625e-05\n",
      "Epoch 48/50\n",
      "335/340 [============================>.] - ETA: 0s - loss: 0.5943 - accuracy: 0.8300\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.5976 - accuracy: 0.8299 - lr: 7.8125e-06\n",
      "Epoch 49/50\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.5840 - accuracy: 0.8386 - lr: 3.9063e-06\n",
      "Epoch 50/50\n",
      "338/340 [============================>.] - ETA: 0s - loss: 0.5984 - accuracy: 0.8351\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "340/340 [==============================] - 1s 4ms/step - loss: 0.5983 - accuracy: 0.8349 - lr: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    callbacks=[create_tensorboard_callback(\"tensorboard_logs\", \"glove6B100D_lstm\"), lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae3c4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Lambda\n",
    "\n",
    "preprocessing_steps = Sequential([\n",
    "    Lambda(lambda x: clean_text(x)),  # Remove URLs\n",
    "    Lambda(lambda x: tokenizer.texts_to_sequences([x])[0]),  # Tokenize the text\n",
    "    Lambda(lambda x: pad_sequences([x], maxlen=max_length-1, padding='pre')[0]),  # Pad the sequences\n",
    "    Lambda(lambda x: tf.expand_dims(x, axis=0))  # Add batch dimension\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "838881aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(result):\n",
    "    return tokenizer.index_word.get(result, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93c413ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "final_model = Sequential([\n",
    "    preprocessing_steps,\n",
    "    model,\n",
    "    layers.Lambda(lambda x: tf.squeeze(x), name='squeeze_output_layer'),\n",
    "    layers.Lambda(lambda x: tf.argmax(x).numpy(), name='argmax_output_layer'),\n",
    "    layers.Lambda(lambda x: generate_output(x), name='generate_output_layer')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b33492a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: First rule of the fight club\n",
      "Generated: First rule of the fight club is you do not talk about fight club\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: Good morning\n",
      "Generated: Good morning i hope you re doing well today today\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: Please\n",
      "Generated: Please prioritize this task to meet the upcoming deadline\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: I will make\n",
      "Generated: I will make sure to get over the rest of the\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "texts = [\"First rule of the fight club\", \"Good morning\", \"Please\", \"I will make\"]\n",
    "\n",
    "for text in texts:\n",
    "    text_copy = text\n",
    "    for _ in range(8):\n",
    "        result = final_model(text_copy)\n",
    "        text_copy += \" \" + result\n",
    "    print(f\"Input: {text}\\nGenerated: {text_copy}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f857d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajat/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "final_model.save(\"Model/glove6B100D_lstm.h5\")\n",
    "pickle.dump(tokenizer, open(\"Model/tokenizer.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
